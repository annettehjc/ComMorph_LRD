# model hyperparameters
SEQUENCE_LENGHT = 32
HIDDEN_SIZE = 512
NUM_HIDDEN_LAYERS = 6
NUM_ATTENTION_HEADS = 8
INTERMEDIATE_SIZE = 1024

# training hyperparameters
NUM_OF_EPOCHS = 3
BATCH_SIZE = 8
LEARNING_RATE = 5e-5
WEIGHT_DECAY = 0.01
SAVE_TOTAL_LIMIT = 2
HIDDEN_DROPOUT_PROB = 0.1
ATTENTION_PROBS_DROPOUT_PROB = 0.1
